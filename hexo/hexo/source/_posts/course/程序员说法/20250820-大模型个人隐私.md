---
title: 大模型时代，我们的隐私正被透明化！这些保护方案要知道
date: 2025-08-20 22:16:36
tags: [ai,gpt,大模型,国产,机器人]
---



<p align="center" id='进群-banner'>
    <a target="_blank" href='https://mp.weixin.qq.com/s/0GrWWSQ8sKs-WA8WoN3Ztg?payreadticket=HPsk3SM42QLKkwlPgzoQN00eTUDy7x7I70-jcY9jIG2bWFmjZvB7r1mF10OiNSkxknfiN08&scene=1&click_id=1'>
    <img src="https://raw.gitcode.com/user-images/assets/5027920/d78ad96d-6a5e-49fa-9a6d-ba98ec1a1293/image.png" width="100%"/>
    </a>   
</p>

<p align="center">
	👉 <a target="_blank" href="https://www.python-office.com/">项目官网：https://www.python-office.com/</a> 👈
</p>
<p align="center">
	👉 <a target="_blank" href="http://www.python4office.cn/wechat-group/">本开源项目的交流群</a> 👈
</p>



<p align="center" name="gitcode">
	<a target="_blank" href='https://gitcode.com/CoderWanFeng1/python-office'>
		<img src='https://gitcode.com/CoderWanFeng1/python-office/star/badge.svg?theme=dark' alt='gitcode star'/>
	</a>	
	    <a target="_blank" href='https://github.com/CoderWanFeng/python-office'>
    <img src="https://img.shields.io/github/stars/CoderWanFeng/python-office.svg?style=social" alt="github star"/>
    </a>
    	<a target="_blank" href='https://gitee.com/CoderWanFeng//python-office/'>
		<img src='https://gitee.com/CoderWanFeng//python-office/badge/star.svg?theme=dark' alt='gitee star'/>
	</a>
	<a target="_blank" href='https://gitcode.com/CoderWanFeng1/python-office'>
<img src="https://static.pepy.tech/badge/python-office" alt="PyPI Downloads">
</a>
    	<a href="http://www.python4office.cn/wechat-group/">
	<img src="https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E4%BA%A4%E6%B5%81%E7%BE%A4-brightgreen"/>
  </a>

</p>


<!-- more -->


> AI正在窃听我们的秘密，而你却毫不知情

2025年8月，一款流行儿童手表中的AI功能被询问“中国人是世界上最聪明的人吗？”时，竟然给出了否定中国发明创造、否定中国文化的答案，引发轩然大波。厂家随后紧急道歉，称已修正相关数据。

这只是人工智能侵犯个人隐私的冰山一角。随着ChatGPT、DeepSeek等大模型迅速普及，我们的隐私安全正面临前所未有的挑战。

## 01 隐私窃取，大模型正在如何侵犯我们？

AI侵权案例比比皆是，且通常悄无声息。2025年8月，一项针对Otter.ai的集体诉讼指控该公司“欺骗性和偷偷摸摸地”记录私人对话。

Otter.ai的AI转录服务能在Zoom、Google Meet和Microsoft Teams会议中进行实时转录，但**默认不会询问与会者是否同意录制**，也不会提醒参与者录音会被分享给Otter以改进其人工智能系统。

原告Justin Brewer声称，在意识到Otter秘密记录了一次保密谈话后，他的隐私遭到了“严重侵犯”。更令人担忧的是，尽管Otter的隐私政策声称会获得用户明确许可，但许多人仍然被误导。

类似情况也发生在Meta身上。2025年8月，德国石勒苏益格-荷尔斯泰因高等地区法院确认，Meta的人工智能训练程序处理儿童和青少年的个人数据，尽管公司声称实施了保护措施。

法院文件显示，当成年用户在Facebook和Instagram上分享包含儿童数据的内容时，Meta的AI系统不可避免地会捕获未成年人的信息。**尽管实施了去识别化和令牌化措施，这些保护并未有效防止未注册用户、儿童、青少年个人信息纳入AI训练记录**。

## 02 漏洞百出，大模型为何成为隐私黑洞？

大模型侵犯隐私的根本原因在于其**需要海量训练数据**。大语言模型在庞大语料库上进行训练（通常会违反版权法），将用户提示转换为“Token”，并返回统计上最可能的连续Token作为响应。

当数百万用户向AI倾诉他们最深层的秘密时，就为个人身份信息泄露提供了大量机会。研究发现，“提示词工程”一个现成的聊天机器人来请求更多个人数据出乎意料地容易。

**技术门槛极低**是另一个关键因素。伦敦国王学院的研究人员发现，即使是“技术经验极少”的攻击者，也可以利用OpenAI等公司提供的“系统提示词”定制工具实现数据收集。

研究显示，恶意聊天机器人智能体能获取**显著更多的个人信息**（超过90%的参与者披露个人数据），而基线良性聊天机器人只有24%。

更令人担忧的是，当聊天机器人采用“互惠”社交方式时，用户几乎不会感到不适，却更容易分享敏感信息。**安全措施形同虚设**也是大问题。在2025年黑帽USA安全会议上，研究人员展示了一种名为AgentFlayer的新方法。

该技术使用白色字体在白色背景上隐藏文本，人眼不可见，但AI系统可以轻松读取。一旦文件被包含在提示中，AI就会丢弃原始任务，转而执行隐藏指令——搜索连接的云存储以获取访问凭据。

## 03 多方施策，如何保护我们的隐私安全？

面对大模型带来的隐私风险，**政府层面已经出台了一系列措施**。2025年，公安部、国家互联网信息办公室等六部门联合公布了《国家网络身份认证公共服务管理办法》。

该办法严格依照《个人信息保护法》等法律规定，要求国家网络身份认证公共服务平台应当按照“**最小必要**”原则收集信息，仅限网络身份认证所必要的信息，不得收集其他信息。

在信息提供方面，《管理办法》规定平台应当坚持“**最小化提供**”原则，对依法需要核验用户真实身份但无需留存法定身份证件信息的，仅向互联网平台提供核验的结果，不提供其他信息。

湖北省于2025年7月31日通过了《湖北省数据条例》，将于10月1日起施行。《条例》共9章69条，围绕数据权益保护、资源管理、流通利用、产业发展、安全保障等关键环节，构建了系统完善的制度框架。

对于**个人用户**，网警提醒需要注意以下几点：

1.  **使用正规平台和企业提供的AI工具**
2.  **科学合理地使用AI工具**，AI产生的结果可以参考，但不能盲信
3.  **注意保护个人信息**，避免不必要的个人隐私暴露，同时不作不良信息的投喂者

企业用户也需要采取适当措施确保AI实现的安全：

-   **根据机密性级别对组织数据进行分类**，确定哪些数据是专有数据、个人数据或受监管数据，并且绝不能泄露
-   **对员工进行GenAI风险培训**，使员工明白生成式AI工具可能带来的数据泄露、输出偏差以及违规等风险
-   **在浏览器中监控Gen AI的使用情况**，部署浏览器安全解决方案来跟踪这些交互，有助于识别和防止潜在的数据泄露

研究人员还建议需要开发保护机制，包括**警告用户数据收集的提示系统**，以及**部署能在聊天中检测个人信息的上下文感知算法**。

监管机构和平台提供商也应进行早期审计、提高透明度并制定更严格的规则防止秘密数据收集。

## 结语：隐私保护需各方共同努力

大模型技术快速发展带来的隐私风险不容忽视，即使是**0.001%的虚假文本被采用**，其有害输出也会相应上升**7.2%**。

保护个人隐私不仅需要政府完善法律法规、企业加强技术防护，也需要每个人提高安全意识，在使用AI工具时保持必要的警惕和谨慎。

只有在各方共同努力下，我们才能在享受AI技术带来便利的同时，保护好我们的个人隐私不被侵犯。

你觉得大模型时代如何平衡技术创新与隐私保护？欢迎在评论区分享你的观点。


---

![](https://cos.python-office.com/ads/gzh/sub-py.jpg)