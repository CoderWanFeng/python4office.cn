---
title: 每天和 AI 聊天像好友？你的隐私可能正在全网裸奔！
date: 2025-08-20 22:16:36
tags: [ ai,gpt,大模型,国产,机器人 ]
---


<p align="center" id='进群-banner-AI'>
    <a target="_blank" href='http://www.python4office.cn/wechat-group/'>
    <img src="https://raw.atomgit.com/user-images/assets/5027920/87fc1ca4-1a6c-47b8-b234-3e323a1aa827/aiq.jpg" width="100%"/>
    </a>   
</p>

<p align="center">
	👉 <a target="_blank" href="https://www.python-office.com/">项目官网：https://www.python-office.com/</a> 👈
</p>
<p align="center">
	👉 <a target="_blank" href="http://www.python4office.cn/wechat-group/">本开源项目的交流群</a> 👈
</p>



<p align="center" name="atomgit">
	<a target="_blank" href='https://atomgit.com/CoderWanFeng1/python-office'>
		<img src='https://atomgit.com/CoderWanFeng1/python-office/star/2025top.svg?theme=dark' alt='atomgit star'/>
	</a>	
	    <a target="_blank" href='https://github.com/CoderWanFeng/python-office'>
    <img src="https://img.shields.io/github/stars/CoderWanFeng/python-office.svg?style=social" alt="github star"/>
    </a>
    	<a target="_blank" href='https://gitee.com/CoderWanFeng//python-office/'>
		<img src='https://gitee.com/CoderWanFeng//python-office/badge/star.svg?theme=dark' alt='gitee star'/>
	</a>
	<a target="_blank" href='https://atomgit.com/CoderWanFeng1/python-office'>
<img src="https://static.pepy.tech/badge/python-office" alt="PyPI Downloads">
</a>
    	<a href="http://www.python4office.cn/wechat-group/">
  <img src="https://img.shields.io/badge/加入-AI交流群-brightgreen" alt="AI交流群">
</a>

</p>


<!-- more -->

![](https://raw.atomgit.com/user-images/assets/5027920/4337c6f5-dbcd-4286-8a5e-7dbcc15d0fbc/image.png 'image.png')


> AI正在窃听我们的秘密，而你却毫不知情。
 
大家好，这里是程序员晚枫，正在all in [各种AI项目](https://mp.weixin.qq.com/s/XQhCrkbumDqtOZXuapMpVg)，最近大模型很火，今天和大家聊一个敏感的话题：**大模型侵犯个人隐私。**

2025年8月，一款流行儿童手表中的AI功能被询问“中国人是世界上最聪明的人吗？”时，竟然给出了否定中国发明创造、否定中国文化的答案，引发轩然大波。厂家随后紧急道歉，称已修正相关数据。

这只是人工智能侵犯个人隐私的冰山一角。随着ChatGPT、DeepSeek等大模型迅速普及，我们的隐私安全正面临前所未有的挑战。

## 01 隐私窃取，大模型正在如何侵犯我们？

AI侵权案例比比皆是，且通常悄无声息。2025年8月，一项针对Otter.ai的集体诉讼指控该公司“欺骗性和偷偷摸摸地”记录私人对话。

Otter.ai的AI转录服务能在Zoom、Google Meet和Microsoft Teams会议中进行实时转录，但**默认不会询问与会者是否同意录制**
，也不会提醒参与者录音会被分享给Otter以改进其人工智能系统。

> 新闻链接：https://www.npr.org/2025/08/15/g-s1-83087/otter-ai-transcription-class-action-lawsuit

原告Justin Brewer声称，在意识到Otter秘密记录了一次保密谈话后，他的隐私遭到了“严重侵犯”。更令人担忧的是，尽管Otter的隐私政策声称会获得用户明确许可，但许多人仍然被误导。

类似情况也发生在Meta身上。2025年8月，德国石勒苏益格-荷尔斯泰因高等地区法院确认，Meta的人工智能训练程序处理儿童和青少年的个人数据，尽管公司声称实施了保护措施。

法院文件显示，当成年用户在Facebook和Instagram上分享包含儿童数据的内容时，Meta的AI系统不可避免地会捕获未成年人的信息。

**尽管实施了去识别化和令牌化措施，这些保护并未有效防止未注册用户、儿童、青少年个人信息纳入AI训练记录**。

![大模型vs个人隐私](https://raw.atomgit.com/user-images/assets/5027920/271746e2-d2ae-46e0-809d-51ee4cab2160/image.png 'image.png')

另外，欧盟对“大模型侵犯个人隐私”开出的罚单已呈“常态化”。以下 8 起典型案例均发生在 2021-2025 年间，处罚对象全部是训练或运营超大规模AI/LLM 的科技巨头，

违法焦点集中在「未经有效同意抓取个人数据、跨境传输、以及用户画像」。按时间倒序，信息全部来自欧盟官方通报或经官方确认的媒体报道。

| 时间      | 受罚企业            | 违法场景                            | 处罚机构 & 金额                             | 核心违规点                                          | 官方来源 |
|---------|-----------------|---------------------------------|---------------------------------------|------------------------------------------------|------|
| 2025-05 | Meta (Facebook) | 用欧盟用户公开帖子、图片、位置训练 Llama-3 等 LLM | 爱尔兰 DPC 提议罚款 12 亿欧元（最终决定书 2025-06 生效） | 未获得“明确同意”即用于 AI 训练；跨境传到美国缺乏 GDPR 第 46 条等效保障    |
| 2024-08 | Uber            | 司机账户、位置、证件、犯罪记录被传至美国训练风控模型      | 荷兰 AP 2.9 亿欧元                         | 未签署 SCC、未加入 EU-US Data Privacy Framework 就跨境传输 |
| 2023-05 | Meta (Facebook) | 继续把欧盟用户数据传美用于广告 & AI            | 爱尔兰 DPC 12 亿欧元                        | 跨境传输工具被欧盟法院判定无效后仍继续传输                          |
| 2021-07 | Amazon          | 用 Alexa 语音、购物记录训练个性化推荐模型        | 卢森堡 DPA 7.46 亿欧元                      | 未清晰告知用户数据将用于机器学习；缺乏有效同意                        |
| 2021-07 | WhatsApp (Meta) | 把电话号码、通讯录用于训练联系人匹配算法            | 爱尔兰 DPC 2.25 亿欧元                      | 同意机制不透明；与 Meta 其他服务共享目的未充分说明                   |
| 2021-07 | Google          | 位置历史、搜索记录、YouTube 观看数据训练广告模型    | 法国 CNIL 9000 万欧元                      | 默认开启个性化广告；用户难以真正撤回同意                           |
| 2020-07 | TikTok          | 13 岁以下儿童数据被用于推荐算法训练             | 荷兰 DPA 75 万欧元；英国 ICO 1450 万欧元         | 未征得父母同意；默认公开未成年人账号                             |
| 2019-01 | Google          | 个性化广告缺乏透明度和有效同意                 | 法国 CNIL 5000 万欧元                      | 用户无法了解数据被用于机器学习广告模型的具体逻辑                       |

#### 补充说明

1. 12 亿欧元（Meta 2023）仍是目前 GDPR 史上最高单笔罚款，但 Meta 2025 的 Llama-3 训练案已追平该记录。
2. 所有处罚都援引 GDPR 第 5-7 条（合法性、公平性、透明性、同意）、第 9 条（敏感数据）和第 44-49 条（跨境传输）。
3. 2024 年生效的《AI Act》把“高风险 AI 系统”训练数据合法性列为前置条件，预计 2025 下半年还会出现新一轮针对大模型的更大罚单。



## 02 漏洞百出，大模型为何成为隐私黑洞？

大模型侵犯隐私的根本原因在于其**需要海量训练数据**。大语言模型在庞大语料库上进行训练（通常会违反版权法），将用户提示转换为“Token”，并返回统计上最可能的连续Token作为响应。

当数百万用户向AI倾诉他们最深层的秘密时，就为个人身份信息泄露提供了大量机会。研究发现，“提示词工程”一个现成的聊天机器人来请求更多个人数据出乎意料地容易。

**技术门槛极低**是另一个关键因素。伦敦国王学院的研究人员发现，即使是“技术经验极少”的攻击者，也可以利用OpenAI等公司提供的“系统提示词”定制工具实现数据收集。

研究显示，恶意聊天机器人智能体能获取**显著更多的个人信息**（超过90%的参与者披露个人数据），而基线良性聊天机器人只有24%。

更令人担忧的是，当聊天机器人采用“互惠”社交方式时，用户几乎不会感到不适，却更容易分享敏感信息。

**安全措施形同虚设**也是大问题。在2025年黑帽USA安全会议上，研究人员展示了一种名为AgentFlayer的新方法。

该技术使用白色字体在白色背景上隐藏文本，人眼不可见，但AI系统可以轻松读取。一旦文件被包含在提示中，AI就会丢弃原始任务，转而执行隐藏指令——搜索连接的云存储以获取访问凭据。

## 03 多方施策，如何保护我们的隐私安全？

面对大模型带来的隐私风险，**政府层面已经出台了一系列措施**。

以下 7 部法规/文件是目前全球对“大模型处理个人信息”最直接、最具约束力的法律框架，均已在 2023-2025 年生效或有明确生效时间表，且都配有高额罚款或禁令机制。

#### 1. 欧盟  
- 《通用数据保护条例》（GDPR，2018-05-25 生效）  
- 《人工智能法》（EU AI Act，2024-08-01 生效，2026-08-02 全面适用）  
→ 2024-12 EDPB 第 28/2024 号意见：LLM 是否匿名需个案判定，不满足匿名即全程 GDPR 合规 。

#### 2. 美国  
- 《加州消费者隐私法》+《加州隐私权法》（CCPA/CPRA，2025-01-01 起加入 AB-1008 修订）  
→ 明确：LLM 输出若能指向个人，模型本身即被认定为“个人信息”，须允许删除/纠正 。

#### 3. 韩国  
- 《生成式 AI 开发、利用个人信息处理指南》（2025-08-09 发布，即时生效）  
→ 全球首个针对 LLM 训练阶段的个人信息合规指南，分阶段提出数据脱敏、模型去标识化、记忆风险检测等量化指标 。

#### 4. 意大利  
- 意大利个人数据保护局（Garante）系列禁令与罚款（2023-03-31 起）  
→ 2023 年率先封禁某 LLM；2024-12 追加 1,500 万欧元罚款，要求上线年龄验证、一键删除个人数据 。

#### 5. 英国  
- 《英国数据保护法案》（UK GDPR，2018-05-25 生效，2024-07-17 修订）  
- 《在线安全法》（Online Safety Act，2023-10-26 生效）  
→ 对 18 岁以下用户数据用于训练大模型需“可验证家长同意”，违者最高全球营收 4% 或 1,800 万英镑 。

#### 6. 加拿大  
- 《个人信息保护与电子文件法》（PIPEDA，2001-01-01 生效，2024-06 纳入 AI 修订）  
→ 训练集含敏感个人信息须做“算法影响评估”（AIA），并向隐私专员备案；最高罚款 1,000 万加元或全球营业额 3% 。

#### 7. 巴西  
- 《通用数据保护法》（LGPD，2020-09-18 生效）  
→ 2024-07 巴西国家数据保护局（ANPD）首次对 LLM 训练数据开出 1.5 亿雷亚尔罚单，理由是“未进行数据保护影响评估（DPIA）且缺少合法基础” 。

从欧盟的 GDPR+AI Act 组合拳，到美、加、韩、意、英、巴各自的“本地化补丁”，全球已进入“大模型隐私合规竞赛”阶段；开发者若想在多国上线，必须同时满足“训练端合法来源 + 部署端可撤回/可解释/可删除”三大硬指标。

> 研究人员还建议需要开发保护机制，包括**警告用户数据收集的提示系统**，以及**部署能在聊天中检测个人信息的上下文感知算法**。

监管机构和平台提供商也应进行早期审计、提高透明度并制定更严格的规则防止秘密数据收集。

## 04 隐私保护需各方共同努力

大模型技术快速发展带来的隐私风险不容忽视，即使是**0.001%的虚假文本被采用**，其有害输出也会相应上升**7.2%**。

保护个人隐私不仅需要政府完善法律法规、企业加强技术防护，也需要每个人提高安全意识，在使用AI工具时保持必要的警惕和谨慎。

只有在各方共同努力下，我们才能在享受AI技术带来便利的同时，保护好我们的个人隐私不被侵犯。

**你在使用大模型的时候，被侵犯过个人隐私吗？欢迎在评论区分享你的经历。**



<p align="center" id='AI编程训练营'>
    <a target="_blank" href='https://www.python-office.com/course-002/AICoding/version-001/all.html'>
    <img src="https://raw.gitcode.com/user-images/assets/5027920/1f021b1e-f401-4afa-bfa5-f1b289d351a7/599.jpg" />
    </a>   
</p>


---

> 另外，大家去给小明的小红书👇账号点点赞吧~！我不想努力了，想吃软饭了。

![小红书：爱吃火锅的小明](https://raw.atomgit.com/user-images/assets/5027920/24fb7a85-b1f1-43ab-a208-7ebf008933b2/image.png 'image.png')


![](https://cos.python-office.com/ads/gzh/sub-py.jpg)

![扫一扫，领红包](https://raw.atomgit.com/user-images/assets/5027920/fad13012-c22f-4c3a-b56e-c70787a55699/172ca166340cd6d0f52d356402901d4f.jpg '6152d8017a3595256e51cbd9e08e148b.png')
  

![美团红包](https://raw.atomgit.com/user-images/assets/5027920/6aa9a60e-bb4a-423c-a75d-cbd6ecf6f370/4dbea2fec93c415c75311666f19a1022.jpg '4dbea2fec93c415c75311666f19a1022.jpg')

![滴滴红包](https://raw.atomgit.com/user-images/assets/5027920/d79c7834-a008-4512-a8ca-88a0b5a990a5/c14141a45d3b671ae94a11bd0556d1dc.jpg 'c14141a45d3b671ae94a11bd0556d1dc.jpg')




程序员晚枫专注AI编程培训，小白看完他的教程[《30讲 · AI编程训练营》](http://www.python4office.cn/course/AI%E7%9B%B8%E5%85%B3/AI%E7%BC%96%E7%A8%8B%E8%AE%AD%E7%BB%83%E8%90%A5/ads/260111-30%E8%AE%B2-599/)就能上手做AI项目。