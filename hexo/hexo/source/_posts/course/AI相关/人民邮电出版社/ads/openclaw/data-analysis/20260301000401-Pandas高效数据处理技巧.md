---
title: Pandasé«˜æ•ˆå¤„ç†ï¼šæˆ‘ç”¨è¿™7ä¸ªæŠ€å·§ï¼ŒæŠŠå¤„ç†é€Ÿåº¦æå‡äº†10å€
date: 2026-03-01 00:04:00
tags: [æ•°æ®åˆ†æ, Pandas, æ€§èƒ½ä¼˜åŒ–, å†…å­˜ä¼˜åŒ–]
---

<p align="center" id='æ‰«ç æŸ¥çœ‹ AI ç¼–ç¨‹è®­ç»ƒè¥'>
    <a target="_blank" href='https://mp.weixin.qq.com/s/uxCILtn9cfIsJR8PqOxlGQ'>
    <img src="https://raw.atomgit.com/user-images/assets/5027920/9209df5a-99d2-40dc-af34-b10b43be9026/12-ai.jpg" />
    </a>   
</p>

<p align="center" name="atomgit">
    <a target="_blank" href='https://github.com/CoderWanFeng/python-office'>
    <img src="https://img.shields.io/github/stars/CoderWanFeng/python-office.svg?style=social" alt="github star"/>
    </a>
    	<a target="_blank" href='https://gitee.com/CoderWanFeng//python-office/'>
		<img src='https://gitee.com/CoderWanFeng//python-office/badge/star.svg?theme=dark' alt='gitee star'/>
	</a>
	<a target="_blank" href='https://atomgit.com/CoderWanFeng1/python-office'>
		<img src='https://atomgit.com/CoderWanFeng1/python-office/star/2025top.svg?theme=dark' alt='atomgit star'/>
	</a>	
	<a target="_blank" href='https://atomgit.com/CoderWanFeng1/python-office'>
<img src="https://static.pepy.tech/badge/python-office" alt="PyPI Downloads">
</a>
<a href="https://mp.weixin.qq.com/s/uxCILtn9cfIsJR8PqOxlGQ">
  <img src="https://img.shields.io/badge/å­¦ä¹ -AI ç¼–ç¨‹-red" alt="AI ç¼–ç¨‹">
</a>
    	<a href="http://www.python4office.cn/wechat-group/">
  <img src="https://img.shields.io/badge/åŠ å…¥-AI äº¤æµç¾¤-brightgreen" alt="AI äº¤æµç¾¤">
</a>

</p>

<!-- more -->

å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯æ­£åœ¨å®æˆ˜å„ç§<a href="https://mp.weixin.qq.com/s/uxCILtn9cfIsJR8PqOxlGQ" target="_blank">AIé¡¹ç›®</a>çš„ç¨‹åºå‘˜æ™šæ«ã€‚

ä»Šå¤©å­¦ä¹ **Pandasæ€§èƒ½ä¼˜åŒ–æŠ€å·§**ã€‚

å½“æ•°æ®é‡è¾¾åˆ°ç™¾ä¸‡ç”šè‡³åƒä¸‡çº§åˆ«æ—¶ï¼Œæ™®é€šçš„Pandasæ“ä½œä¼šå˜å¾—å¾ˆæ…¢ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä½ èƒ½ç”¨æ›´å°‘çš„å†…å­˜ã€æ›´å¿«çš„é€Ÿåº¦å¤„ç†å¤§æ•°æ®ã€‚

---

## æŠ€å·§1ï¼šä½¿ç”¨åˆé€‚çš„æ•°æ®ç±»å‹

### æ•°å€¼ç±»å‹ä¼˜åŒ–
```python
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({
    'int_col': np.random.randint(0, 100, 1000000),
    'float_col': np.random.randn(1000000),
    'bool_col': np.random.choice([True, False], 1000000)
})

print("åŸå§‹å†…å­˜å ç”¨:")
print(df.memory_usage(deep=True).sum() / 1024**2, "MB")

# ä¼˜åŒ–æ•´æ•°ç±»å‹
df['int_col'] = df['int_col'].astype('int8')  # å¦‚æœèŒƒå›´æ˜¯0-255
# æˆ– int16, int32 æ ¹æ®å®é™…èŒƒå›´é€‰æ‹©

# ä¼˜åŒ–æµ®ç‚¹æ•°
df['float_col'] = df['float_col'].astype('float32')

print("\nä¼˜åŒ–åå†…å­˜å ç”¨:")
print(df.memory_usage(deep=True).sum() / 1024**2, "MB")
```

### ç±»åˆ«ç±»å‹ï¼ˆCategoryï¼‰
```python
# å­—ç¬¦ä¸²åˆ—å ç”¨å¤§é‡å†…å­˜
df['category'] = np.random.choice(['A', 'B', 'C', 'D'], 1000000)

# è½¬ä¸ºcategoryç±»å‹
df['category'] = df['category'].astype('category')

# å†…å­˜å‡å°‘90%ä»¥ä¸Šï¼
```

---

## æŠ€å·§2ï¼šé¿å…å¾ªç¯ï¼Œä½¿ç”¨å‘é‡åŒ–

### âŒ æ…¢ï¼šPythonå¾ªç¯
```python
# è®¡ç®—ä¸¤åˆ—çš„æ¬§æ°è·ç¦»ï¼ˆæ…¢ï¼‰
def calc_distance(row):
    return (row['x']**2 + row['y']**2)**0.5

df['distance'] = df.apply(calc_distance, axis=1)  # è¶…æ…¢ï¼
```

### âœ… å¿«ï¼šå‘é‡åŒ–è¿ç®—
```python
# ä½¿ç”¨å‘é‡åŒ–ï¼ˆå¿«100å€ï¼‰
df['distance'] = (df['x']**2 + df['y']**2)**0.5
```

### å…¶ä»–å‘é‡åŒ–æ›¿ä»£æ–¹æ¡ˆ
```python
# æ¡ä»¶èµ‹å€¼
# æ…¢
for i in range(len(df)):
    if df.loc[i, 'score'] > 80:
        df.loc[i, 'grade'] = 'A'

# å¿«
df.loc[df['score'] > 80, 'grade'] = 'A'
df['grade'] = np.where(df['score'] > 80, 'A', 'B')
```

---

## æŠ€å·§3ï¼šä½¿ç”¨evalå’Œquery

```python
# å¤æ‚è¡¨è¾¾å¼åŠ é€Ÿ
import numexpr

# æ™®é€šæ–¹å¼ï¼ˆæ…¢ï¼‰
df['result'] = df['a'] + df['b'] * df['c'] - df['d'] / df['e']

# ä½¿ç”¨evalï¼ˆå¿«2-3å€ï¼‰
df['result'] = pd.eval('df.a + df.b * df.c - df.d / df.e')

# queryåŠ é€Ÿç­›é€‰
# æ…¢
df[(df['a'] > 0) & (df['b'] < 100)]

# å¿«
df.query('a > 0 and b < 100')
```

---

## æŠ€å·§4ï¼šåˆ†å—è¯»å–å¤§æ–‡ä»¶

```python
# å†…å­˜ä¸è¶³æ—¶ï¼Œåˆ†å—å¤„ç†
chunk_size = 100000
results = []

for chunk in pd.read_csv('huge_file.csv', chunksize=chunk_size):
    # å¤„ç†æ¯ä¸ªå—
    processed = chunk.groupby('category')['value'].sum()
    results.append(processed)

# åˆå¹¶ç»“æœ
final_result = pd.concat(results).groupby(level=0).sum()
```

---

## æŠ€å·§5ï¼šä½¿ç”¨è¿­ä»£å™¨

```python
# éå†DataFrameï¼ˆä¸è¦ç”¨iterrowsï¼‰

# âŒ æ…¢ï¼šiterrows
for index, row in df.iterrows():
    print(row['column'])

# âœ… å¿«ï¼šitertuples
for row in df.itertuples():
    print(row.column)

# âœ… æ›´å¿«ï¼šç›´æ¥éå†åˆ—
for value in df['column']:
    print(value)
```

---

## æŠ€å·§6ï¼šåŠæ—¶é‡Šæ”¾å†…å­˜

```python
# åˆ é™¤ä¸éœ€è¦çš„å˜é‡
del large_df

# å¼ºåˆ¶åƒåœ¾å›æ”¶
import gc
gc.collect()

# åªé€‰æ‹©éœ€è¦çš„åˆ—
df = df[['col1', 'col2', 'col3']]  # è€Œä¸æ˜¯åŠ è½½æ‰€æœ‰åˆ—
```

---

## æŠ€å·§7ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®æ ¼å¼

```python
# CSV vs Parquet
# Parquetæ˜¯åˆ—å¼å­˜å‚¨ï¼Œè¯»å–æ›´å¿«ã€å‹ç¼©ç‡æ›´é«˜

# ä¿å­˜ä¸ºParquet
df.to_parquet('data.parquet', compression='snappy')

# è¯»å–Parquetï¼ˆæ¯”CSVå¿«5-10å€ï¼‰
df = pd.read_parquet('data.parquet')

# å…¶ä»–é«˜æ•ˆæ ¼å¼
# Featherï¼šè¯»å†™æå¿«
# HDF5ï¼šé€‚åˆå¤§æ•°ç»„æ•°æ®
```

---

## å®æˆ˜ï¼šå®Œæ•´ä¼˜åŒ–æµç¨‹

```python
import pandas as pd
import numpy as np

def optimize_dataframe(df):
    """è‡ªåŠ¨ä¼˜åŒ–DataFrame"""
    
    # 1. ä¼˜åŒ–æ•°å€¼ç±»å‹
    for col in df.select_dtypes(include=['int']).columns:
        c_min = df[col].min()
        c_max = df[col].max()
        if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
            df[col] = df[col].astype(np.int8)
        elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
            df[col] = df[col].astype(np.int16)
        elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
            df[col] = df[col].astype(np.int32)
    
    # 2. ä¼˜åŒ–æµ®ç‚¹æ•°
    for col in df.select_dtypes(include=['float']).columns:
        df[col] = df[col].astype(np.float32)
    
    # 3. ä¼˜åŒ–å¯¹è±¡ç±»å‹
    for col in df.select_dtypes(include=['object']).columns:
        num_unique = df[col].nunique()
        num_total = len(df[col])
        if num_unique / num_total < 0.5:  # é‡å¤å€¼å¤š
            df[col] = df[col].astype('category')
    
    return df

# ä½¿ç”¨
print("ä¼˜åŒ–å‰å†…å­˜:", df.memory_usage(deep=True).sum() / 1024**2, "MB")
df = optimize_dataframe(df)
print("ä¼˜åŒ–åå†…å­˜:", df.memory_usage(deep=True).sum() / 1024**2, "MB")
```

---

## ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†è¿›å…¥**æ•°æ®å¯è§†åŒ–**éƒ¨åˆ†ï¼Œå­¦ä¹ MatplotlibåŸºç¡€ã€‚

ğŸ‘‰ **[ç»§ç»­é˜…è¯»ï¼šMatplotlibåŸºç¡€-ç»˜åˆ¶ä½ çš„ç¬¬ä¸€å¼ å›¾è¡¨](/course/AIç›¸å…³/äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾/ads/openclaw/data-analysis/20260301000501-MatplotlibåŸºç¡€-ç»˜åˆ¶ä½ çš„ç¬¬ä¸€å¼ å›¾è¡¨/)**

---

## ğŸ’¬ åŠ å…¥å­¦ä¹ äº¤æµç¾¤

æ‰«ç åŠ å…¥**Pythonå­¦ä¹ äº¤æµç¾¤**ï¼Œå’Œæ•°åƒååŒå­¦ä¸€èµ·è¿›æ­¥ï¼š

ğŸ‘‰ **[ç‚¹å‡»åŠ å…¥äº¤æµç¾¤](http://www.python4office.cn/wechat-group/)**

ç¾¤é‡Œä¸å®šæœŸåˆ†äº«ï¼š
- æ•°æ®åˆ†æå®æˆ˜æ¡ˆä¾‹
- Pythonå­¦ä¹ èµ„æ–™
- æ±‚èŒé¢è¯•ç»éªŒ
- è¡Œä¸šæœ€æ–°åŠ¨æ€

---

## æ¨èï¼šAI Pythonæ•°æ®åˆ†æå®æˆ˜è¥

ğŸ **é™æ—¶ç¦åˆ©**ï¼šé€ã€Šåˆ©ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æã€‹å®ä½“ä¹¦

ğŸ‘‰ **[ç‚¹å‡»äº†è§£è¯¦æƒ…](https://mp.weixin.qq.com/s/uxCILtn9cfIsJR8PqOxlGQ)**

---

## è¯¾ç¨‹å¯¼èˆª

**ä¸Šä¸€ç¯‡ï¼š** [Pandaså­—ç¬¦ä¸²å¤„ç†æŠ€å·§](/course/AIç›¸å…³/äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾/ads/openclaw/data-analysis/20260301000301-Pandaså­—ç¬¦ä¸²å¤„ç†æŠ€å·§/)

**ä¸‹ä¸€ç¯‡ï¼š** [MatplotlibåŸºç¡€-ç»˜åˆ¶ä½ çš„ç¬¬ä¸€å¼ å›¾è¡¨](/course/AIç›¸å…³/äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾/ads/openclaw/data-analysis/20260301000501-MatplotlibåŸºç¡€-ç»˜åˆ¶ä½ çš„ç¬¬ä¸€å¼ å›¾è¡¨/)

---

*PSï¼šæ€§èƒ½ä¼˜åŒ–æ˜¯è¿›é˜¶å¿…å¤‡æŠ€èƒ½ã€‚è®°ä½ï¼šèƒ½ç”¨å‘é‡åŒ–å°±ä¸ç”¨å¾ªç¯ï¼Œèƒ½ç”¨categoryå°±ä¸ç”¨objectã€‚*
